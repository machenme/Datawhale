{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第一步**\n",
    "在运行环境中安装对应的库、数据集，并解压到对应的目录\n",
    "执行命令即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:38:22.240840Z",
     "iopub.status.busy": "2024-07-24T16:38:22.240506Z",
     "iopub.status.idle": "2024-07-24T16:39:48.076470Z",
     "shell.execute_reply": "2024-07-24T16:39:48.075796Z",
     "shell.execute_reply.started": "2024-07-24T16:38:22.240812Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting xarray[complete]\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ce/78/7a78d5197e409371c4fd9734ad9ab41ed6f9147b3ac23256c4e6c81295f2/xarray-2024.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (1.26.3)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (23.1)\n",
      "Requirement already satisfied: pandas>=2.0 in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0->xarray[complete]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0->xarray[complete]) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0->xarray[complete]) (2023.4)\n",
      "Collecting hypothesis (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/4d/a7/8ec00d12fc4a7a9deb6000edf74342e831e5b4b707646dbd2cd8704bbad8/hypothesis-6.108.4-py3-none-any.whl (465 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.2/465.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mypy (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/40/93/2d36405a6a0c512cd167200f483af3bd14d15717a33ba60bf4dd5ce4b4bc/mypy-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pre-commit in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (3.7.0)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (8.1.1)\n",
      "Collecting pytest-cov (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/78/3a/af5b4fa5961d9a1e6237b530eb87dd04aea6eb83da09d2a4073d81b54ccf/pytest_cov-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting pytest-env (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/25/b2/bdc663a5647ce2034f7e8420122af340df87c01ba97745fc753b8c917acb/pytest_env-1.1.3-py3-none-any.whl (6.2 kB)\n",
      "Collecting pytest-xdist (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6d/82/1d96bf03ee4c0fdc3c0cbe61470070e659ca78dc0086fb88b66c185e2449/pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytest-timeout (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/03/27/14af9ef8321f5edc7527e47def2a21d8118c6f329a9342cc61387a0c0599/pytest_timeout-2.3.1-py3-none-any.whl (14 kB)\n",
      "Collecting ruff (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a1/02/64f24893eea23c447460e6509e9dd0ae18d7a797f67fee1bafed964ebbae/ruff-0.5.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (3.5.3)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (0.13.2)\n",
      "Collecting nc-time-axis (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/01/89/dbeab77a217f8fbda97a637acf1e3f0ce8c9c9fb3f5e5d1ff843da859520/nc_time_axis-1.4.1-py3-none-any.whl (17 kB)\n",
      "Collecting dask[complete] (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/5f/83/1b4cc731fa8550a3041adf1c8e149a318dfee542d6f59a1940552e06df87/dask-2024.7.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (1.11.4)\n",
      "Collecting bottleneck (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/31/ca/52730df3ae53dddc38ef234863e104c45c71efd94670abb1b673b8f4224b/Bottleneck-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (356 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.2/356.2 kB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numbagg (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9c/1e/4cf1475d48bee892dd09826ffa28c0fe68e87700db2526245edc54407681/numbagg-0.8.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flox (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/af/6b/b347143072d0a6c564ee617068851cf4b3709a3f02d028816f90f32738d2/flox-0.9.8-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (3.3.0)\n",
      "Collecting netCDF4 (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/22/31/98f76169e039d3195dccfc7235a82ec33334efc1564051b25aac567e7bc3/netCDF4-1.7.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5netcdf (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/68/2d/63851081b19d1ccf245091255797cb358c53c886609b5056da5457f7dbbf/h5netcdf-1.3.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zarr (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/5d/bd/8d881d8ca6d80fcb8da2b2f94f8855384daf649499ddfba78ffd1ee2caa3/zarr-2.18.2-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (2023.10.0)\n",
      "Collecting cftime (from xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/56/9b/b020a7fac001782d9a71e25b4702084c3a5d5bdaa73ca3e4f3516e196746/cftime-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from xarray[complete]) (1.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->xarray[complete]) (1.16.0)\n",
      "Requirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask[complete]; extra == \"parallel\"->xarray[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]; extra == \"parallel\"->xarray[complete]) (3.0.0)\n",
      "Collecting partd>=1.4.0 (from dask[complete]; extra == \"parallel\"->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/71/e7/40fb618334dcdf7c5a316c0e7343c5cd82d3d866edc100d98e29bc945ecd/partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask[complete]; extra == \"parallel\"->xarray[complete]) (6.0.1)\n",
      "Collecting toolz>=0.10.0 (from dask[complete]; extra == \"parallel\"->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b7/8a/d82202c9f89eab30f9fc05380daae87d617e2ad11571ab23d7c13a29bb54/toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]; extra == \"parallel\"->xarray[complete]) (7.0.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]; extra == \"parallel\"->xarray[complete]) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from dask[complete]; extra == \"parallel\"->xarray[complete]) (0.6)\n",
      "Collecting lz4>=4.3.2 (from dask[complete]; extra == \"parallel\"->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/cf/50/75c8f966dbcc524e7253f99b8e04c6cad7328f517eb0323abf8b4068f5bb/lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy-groupies>=0.9.19 (from flox->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e8/6a/44b12ad6614b736122c01345874434932365572dca8a20d4a74dca2b61e8/numpy_groupies-0.11.1-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from h5netcdf->xarray[complete]) (3.10.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis->xarray[complete]) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis->xarray[complete]) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis->xarray[complete]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->xarray[complete]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->xarray[complete]) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->xarray[complete]) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->xarray[complete]) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->xarray[complete]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from mypy->xarray[complete]) (4.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mypy->xarray[complete]) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from mypy->xarray[complete]) (2.0.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from netCDF4->xarray[complete]) (2023.11.17)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from numbagg->xarray[complete]) (0.58.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch->xarray[complete]) (4.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch->xarray[complete]) (2.31.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pre-commit->xarray[complete]) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pre-commit->xarray[complete]) (2.5.36)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from pre-commit->xarray[complete]) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.10/site-packages (from pre-commit->xarray[complete]) (20.25.3)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->xarray[complete]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->xarray[complete]) (1.5.0)\n",
      "Collecting coverage>=5.2.1 (from coverage[toml]>=5.2.1->pytest-cov->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b1/7b/5ddf82c7bac217d2343efbd36657a3d848a8670f983767ffe2d3212b76bc/coverage-7.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting execnet>=2.1 (from pytest-xdist->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/43/09/2aea36ff60d16dd8879bdb2f5b3ee0ba8d08cbbdcdfe870e695ce3784385/execnet-2.1.1-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting asciitree (from zarr->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2d/6a/885bc91484e1aa8f618f6f0228d76d0e67000b0fdd6090673b777e311913/asciitree-0.3.3.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numcodecs>=0.10.0 (from zarr->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e9/1a/7f36f6868a6f8752f90eb2f1dece0b3e7cb1b1a07308865054388eff4c3d/numcodecs-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fasteners (from zarr->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/61/bf/fd60001b3abc5222d8eaa4a204cd8c0ae78e75adc688f33ce4bf25b7fafa/fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[complete]; extra == \"parallel\"->xarray[complete]) (3.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nodeenv>=0.11.1->pre-commit->xarray[complete]) (68.0.0)\n",
      "Collecting locket (from partd>=1.4.0->dask[complete]; extra == \"parallel\"->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/db/bc/83e112abc66cd466c6b83f99118035867cecd41802f8d044638aa78a106e/locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[complete]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[complete]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[complete]) (1.26.16)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->xarray[complete]) (0.3.8)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->xarray[complete]) (3.13.1)\n",
      "Collecting distributed==2024.7.1 (from dask[complete]->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c7/b5/44d239f23f74e9705c22e4ee0e665dbb44e0d63f8eefc7a002c9b7413ea2/distributed-2024.7.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bokeh>=2.4.2 (from dask[complete]->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/21/9d/83604f0973a7e28f3309c24c888b68a293d1abfddadcdbbac5a77f2e9d96/bokeh-3.5.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from dask[complete]->xarray[complete]) (3.1.2)\n",
      "Collecting dask-expr<1.2,>=1.1 (from dask[complete]->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/09/d0/56eb2b34c08f81f16fdde1d2e2fef6c8b10dff38d436cc23c9b6174024b2/dask_expr-1.1.9-py3-none-any.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.7.1->dask[complete]->xarray[complete]) (1.0.7)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.7.1->dask[complete]->xarray[complete]) (5.9.7)\n",
      "Collecting tblib>=1.6.0 (from distributed==2024.7.1->dask[complete]->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9b/87/ce70db7cae60e67851eb94e1a2127d4abb573d3866d2efd302ceb0d4d2a5/tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.7.1->dask[complete]->xarray[complete]) (6.4)\n",
      "Collecting zict>=3.0.0 (from distributed==2024.7.1->dask[complete]->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/80/ab/11a76c1e2126084fde2639514f24e6111b789b0bfa4fc6264a8975c7e1f1/zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->numbagg->xarray[complete]) (0.41.1)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]->xarray[complete]) (1.2.0)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh>=2.4.2->dask[complete]->xarray[complete])\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/5f/51/c106f095c33de0b833d3823fbab3383248476b3a9fd4dcd59ba01d950361/xyzservices-2024.6.0-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->dask[complete]->xarray[complete]) (2.1.3)\n",
      "Building wheels for collected packages: asciitree\n",
      "  Building wheel for asciitree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5048 sha256=75296311206768d24e1818be9b77ff9c73e988e2089340d53df45952cf6d3b9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/2f/f3/6b399cb84d149af70fa3d0170565b3c696c2fee43474f0825f\n",
      "Successfully built asciitree\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: asciitree, zict, xyzservices, toolz, tblib, ruff, numpy-groupies, numcodecs, mypy, lz4, locket, hypothesis, fasteners, execnet, coverage, cftime, bottleneck, zarr, pytest-xdist, pytest-timeout, pytest-env, partd, numbagg, netCDF4, h5netcdf, xarray, pytest-cov, nc-time-axis, flox, dask, bokeh, distributed, dask-expr\n",
      "Successfully installed asciitree-0.3.3 bokeh-3.5.0 bottleneck-1.4.0 cftime-1.6.4 coverage-7.6.0 dask-2024.7.1 dask-expr-1.1.9 distributed-2024.7.1 execnet-2.1.1 fasteners-0.19 flox-0.9.8 h5netcdf-1.3.0 hypothesis-6.108.4 locket-1.0.0 lz4-4.3.3 mypy-1.11.0 nc-time-axis-1.4.1 netCDF4-1.7.1.post1 numbagg-0.8.1 numcodecs-0.13.0 numpy-groupies-0.11.1 partd-1.4.2 pytest-cov-5.0.0 pytest-env-1.1.3 pytest-timeout-2.3.1 pytest-xdist-3.6.1 ruff-0.5.4 tblib-3.0.0 toolz-0.12.1 xarray-2024.6.0 xyzservices-2024.6.0 zarr-2.18.2 zict-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "获取:1 http://mirrors.aliyun.com/ubuntu jammy InRelease [270 kB]\n",
      "获取:2 http://mirrors.aliyun.com/ubuntu jammy-security InRelease [129 kB]        m\n",
      "获取:3 http://mirrors.aliyun.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "获取:4 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "获取:5 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2204/x86_64  Packages [859 kB]\n",
      "获取:6 http://mirrors.aliyun.com/ubuntu jammy-backports InRelease [127 kB]3m\n",
      "获取:7 http://mirrors.aliyun.com/ubuntu jammy/universe amd64 Packages [17.5 MB]3m\n",
      "获取:8 http://mirrors.aliyun.com/ubuntu jammy/restricted amd64 Packages [164 kB] 0mm\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:9 http://mirrors.aliyun.com/ubuntu jammy/main amd64 Packages [1,792 kB]     0m\u001b[33m\n",
      "获取:10 http://mirrors.aliyun.com/ubuntu jammy/multiverse amd64 Packages [266 kB]0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:11 http://mirrors.aliyun.com/ubuntu jammy-security/universe amd64 Packages [1,128 kB]33m\n",
      "获取:12 http://mirrors.aliyun.com/ubuntu jammy-security/main amd64 Packages [2,073 kB]3m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:13 http://mirrors.aliyun.com/ubuntu jammy-security/restricted amd64 Packages [2,721 kB]m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:14 http://mirrors.aliyun.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]3m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:15 http://mirrors.aliyun.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]33m\n",
      "获取:16 http://mirrors.aliyun.com/ubuntu jammy-updates/main amd64 Packages [2,338 kB]33m\n",
      "获取:17 http://mirrors.aliyun.com/ubuntu jammy-updates/restricted amd64 Packages [2,795 kB]3m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:18 http://mirrors.aliyun.com/ubuntu jammy-updates/universe amd64 Packages [1,418 kB][33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:19 http://mirrors.aliyun.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "获取:20 http://mirrors.aliyun.com/ubuntu jammy-backports/main amd64 Packages [81.0 kB]3m\n",
      "已下载 33.9 MB，耗时 1分 4秒 (533 kB/s)                                                0m\u001b[33m\n",
      "正在读取软件包列表... 完成%\n",
      "正在分析软件包的依赖关系树... 完成%\n",
      "正在读取状态信息... 完成                   \n",
      "有 159 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\n",
      "正在读取软件包列表... 完成%\n",
      "正在分析软件包的依赖关系树... 完成%\n",
      "正在读取状态信息... 完成                   \n",
      "下列【新】软件包将被安装：\n",
      "  axel\n",
      "升级了 0 个软件包，新安装了 1 个软件包， 要卸载 0 个软件包，有 159 个软件包未被升级。\n",
      "需要下载 58.7 kB 的归档。\n",
      "解压缩后会消耗 204 kB 的额外空间。\n",
      "获取:1 http://mirrors.aliyun.com/ubuntu jammy/universe amd64 axel amd64 2.17.11-1 [58.7 kB]\n",
      "已下载 58.7 kB，耗时 0秒 (312 kB/s)\u001b[0m\u001b[33m\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1A正在选中未选择的软件包 axel。\n",
      "(正在读取数据库 ... 系统当前共安装有 79140 个文件和目录。)\n",
      "准备解压 .../axel_2.17.11-1_amd64.deb  ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30m进度：[  0%]\u001b[49m\u001b[39m [..............................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30m进度：[ 20%]\u001b[49m\u001b[39m [############..................................................] \u001b8正在解压 axel (2.17.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30m进度：[ 40%]\u001b[49m\u001b[39m [########################......................................] \u001b8正在设置 axel (2.17.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30m进度：[ 60%]\u001b[49m\u001b[39m [#####################################.........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30m进度：[ 80%]\u001b[49m\u001b[39m [#################################################.............] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "# !pip install xarray[complete]\n",
    "# !apt update&&apt install axel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:39:50.897185Z",
     "iopub.status.busy": "2024-07-24T16:39:50.896851Z",
     "iopub.status.idle": "2024-07-24T16:42:19.538847Z",
     "shell.execute_reply": "2024-07-24T16:42:19.538214Z",
     "shell.execute_reply.started": "2024-07-24T16:39:50.897152Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing download: https://tianchi-race-prod-sh.oss-cn-shanghai.aliyuncs.com/file/race/documents/532234/bigFile/weather.round1.train.gt.2019-2021.zip?Expires=1721852797&OSSAccessKeyId=LTAI5t7fj2oKqzKgLGz6kGQc&Signature=%2B4JoTbsP%2FQuqmG%2FZbWWH2oYZPRM%3D&response-content-disposition=attachment%3B%20\n",
      "File size: 139.237 Megabyte(s) (146000256 bytes)\n",
      "Opening output file weather.round1.train.gt.2019-2021.zip\n",
      "Starting download\n",
      "\n",
      "Connection 0 finished1     ..........2....3    ........4  ] [ 148.7MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished1  0  ...............3    ........4  ] [ 148.7MB/s] [00:00]\u001b[2K\n",
      "Connection 4 finished1  0  ...............3  2 ...........] [ 157.2MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished..1.04..................3 ...........] [ 136.9MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished...1..4.................23...........] [ 140.0MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished...1..4.................23...........] [ 141.2MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished......4..................31..........] [ 135.5MB/s] [00:00]\u001b[2K\n",
      "Connection 4 finished.........................31..........] [ 136.0MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished.........................24..........] [ 116.8MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished..........................4..........] [ 116.8MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished..........................4..........] [ 115.3MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished..........................4..........] [ 104.8MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished..........................4..........] [ 104.6MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished..........................4..........] [ 104.7MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished..........................4..........] [  95.7MB/s] [00:00]\u001b[2K\n",
      "Connection 4 finished..........................4..........] [  94.4MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished..........................4..........] [  94.4MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished..........................4..........] [  94.0MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished..........................4..........] [  87.4MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished\n",
      "Connection 0 finished..........................4..........] [  87.0MB/s] [00:00]\u001b[2K\n",
      "[100%] [..................................................] [  77.4MB/s] [00:00]\n",
      "\n",
      "Downloaded 139.237 Megabyte(s) in 1 second(s). (79221.87 KB/s)\n",
      "Initializing download: https://tianchi-race-prod-sh.oss-cn-shanghai.aliyuncs.com/file/race/documents/532234/bigFile/weather.round1.test.zip?Expires=1721853230&OSSAccessKeyId=LTAI5t7fj2oKqzKgLGz6kGQc&Signature=AGbaVGl%2BC7EdWBlKKnOkcJ5hJu0%3D&response-content-disposition=attachment%3B%20\n",
      "File size: 5.88844 Gigabyte(s) (6322667532 bytes)\n",
      "Opening output file weather.round1.test.zip\n",
      "Starting download\n",
      "\n",
      "Connection 0 finished......1.........2.........3.........4] [  41.4MB/s] [00:00]\u001b[2K [  51.6MB/s] [01:27]\n",
      "Connection 4 finished......1.........2.........3..........] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished......4...................3..........] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished......4..............................] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 4 finished......4..............................] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished......4..............................] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished......4..............................] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished......4..............................] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished......4..............................] [  41.4MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 4 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished......4..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished......3..............................] [  41.3MB/s] [00:00]\u001b[2K\n",
      "Connection 4 finished\n",
      "[100%] [..................................................] [  41.3MB/s] [00:00]\n",
      "\n",
      "Downloaded 5.88844 Gigabyte(s) in 2:26 minute(s). (42267.59 KB/s)\n"
     ]
    }
   ],
   "source": [
    "# !axel -n 5 -o weather.round1.train.gt.2019-2021.zip 'https://tianchi-race-prod-sh.oss-cn-shanghai.aliyuncs.com/file/race/documents/532234/bigFile/weather.round1.train.gt.2019-2021.zip?Expires=1721908298&OSSAccessKeyId=LTAI5t7fj2oKqzKgLGz6kGQc&Signature=PHY8yu0xUzWjVqBfpVNPAVr5MCM%3D&response-content-disposition=attachment%3B%20'\n",
    "\n",
    "# !axel -n 5 -o weather.round1.test.zip 'https://tianchi-race-prod-sh.oss-cn-shanghai.aliyuncs.com/file/race/documents/532234/bigFile/weather.round1.test.zip?Expires=1721908392&OSSAccessKeyId=LTAI5t7fj2oKqzKgLGz6kGQc&Signature=wOhZYyc2meJj5UrIvKyYRiW3oYs%3D&response-content-disposition=attachment%3B%20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:42:19.540088Z",
     "iopub.status.busy": "2024-07-24T16:42:19.539787Z",
     "iopub.status.idle": "2024-07-24T16:43:38.751940Z",
     "shell.execute_reply": "2024-07-24T16:43:38.751223Z",
     "shell.execute_reply.started": "2024-07-24T16:42:19.540070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q -n weather.round1.train.gt.2019-2021.zip -d groundtruth\n",
    "!unzip -q -n weather.round1.test.zip -d test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第二步**\n",
    "导入运行所需要的库函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T16:39:48.078058Z",
     "iopub.status.busy": "2024-07-24T16:39:48.077799Z",
     "iopub.status.idle": "2024-07-24T16:39:50.896148Z",
     "shell.execute_reply": "2024-07-24T16:39:50.895640Z",
     "shell.execute_reply.started": "2024-07-24T16:39:48.078039Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第三步**\n",
    "数据集路径配置设置\n",
    "- 比赛的数据部分分为**数据特征**和**数据真值**两部分，数据特征是模型训练的**输入**，数据真值是模型训练的**标签**\n",
    "- 其中数据特征部分 输入的路径目录下包含年份文件夹 \n",
    " - 例如示例给出的 \"输入路径/2021/...\" 各年份文件夹下包含从官网下载的压缩包(e.g. weather.round1.train.ft.2021.1.zip) 解压后文件夹下有不同时段的数据文件夹(e.g. 20210101-00), 内部包含6个nc文件, 是从伏羲大模型中获取的从第6小时到第72小时的数据\n",
    "\n",
    "- 数据真值部分 输入的路径目录下包含3个年份的.nc数据, 其中选择哪些年份的特征数据作为输入, 就在years中添加哪些年份\n",
    "- fcst_steps指预测的时间步长, 从第1小时到第72小时, 间隔为1小时\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:38.753060Z",
     "iopub.status.busy": "2024-07-24T16:43:38.752816Z",
     "iopub.status.idle": "2024-07-24T16:43:38.756355Z",
     "shell.execute_reply": "2024-07-24T16:43:38.755723Z",
     "shell.execute_reply.started": "2024-07-24T16:43:38.753043Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path config\n",
    "feature_path = 'feature' #自定义路径并修改为自己的路径\n",
    "gt_path = 'groundtruth' #自定义路径并修改为自己的路径\n",
    "years = ['2021']\n",
    "fcst_steps = list(range(1, 73, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第四步**\n",
    "Feature类和GroundTruth类是数据集的定义\n",
    "方便后续自定义数据集和数据加载类, 方便我们训练时取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:38.757295Z",
     "iopub.status.busy": "2024-07-24T16:43:38.757084Z",
     "iopub.status.idle": "2024-07-24T16:43:42.071799Z",
     "shell.execute_reply": "2024-07-24T16:43:42.071309Z",
     "shell.execute_reply.started": "2024-07-24T16:43:38.757279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature部分\n",
    "class Feature:\n",
    "    def __init__(self):\n",
    "        self.path = feature_path\n",
    "        self.years = years\n",
    "        self.fcst_steps = fcst_steps\n",
    "        self.features_paths_dict = self.get_features_paths()\n",
    "\n",
    "    def get_features_paths(self):\n",
    "        init_time_path_dict = {}\n",
    "        for year in self.years:\n",
    "            init_time_dir_year = os.listdir(os.path.join(self.path, year))\n",
    "            for init_time in sorted(init_time_dir_year):\n",
    "                init_time_path_dict[pd.to_datetime(init_time)] = os.path.join(self.path, year, init_time)\n",
    "        return init_time_path_dict\n",
    "\n",
    "    def get_fts(self, init_time):\n",
    "        return xr.open_mfdataset(self.features_paths_dict.get(init_time) + '/*').sel(lead_time=self.fcst_steps).isel(\n",
    "            time=0)\n",
    "    \n",
    "# GroundTruth部分\n",
    "class GT:\n",
    "    def __init__(self):\n",
    "        self.path = gt_path\n",
    "        self.years = years\n",
    "        self.fcst_steps = fcst_steps\n",
    "        self.gt_paths = [os.path.join(self.path, f'{year}.nc') for year in self.years]\n",
    "        self.gts = xr.open_mfdataset(self.gt_paths)\n",
    "\n",
    "    def parser_gt_timestamps(self, init_time):\n",
    "        return [init_time + pd.Timedelta(f'{fcst_step}h') for fcst_step in self.fcst_steps]\n",
    "\n",
    "    def get_gts(self, init_time):\n",
    "\n",
    "        return self.gts.sel(time=self.parser_gt_timestamps(init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第五步**\n",
    "mydataset类的定义, 整合了加载特征和特征对应真值的功能, 方便后续训练时取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:42.073591Z",
     "iopub.status.busy": "2024-07-24T16:43:42.073373Z",
     "iopub.status.idle": "2024-07-24T16:43:42.077541Z",
     "shell.execute_reply": "2024-07-24T16:43:42.077019Z",
     "shell.execute_reply.started": "2024-07-24T16:43:42.073575Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建Dataset部分\n",
    "class mydataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ft = Feature()\n",
    "        self.gt = GT()\n",
    "        self.features_paths_dict = self.ft.features_paths_dict\n",
    "        self.init_times = list(self.features_paths_dict.keys())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        init_time = self.init_times[index]\n",
    "        ft_item = self.ft.get_fts(init_time).to_array().isel(variable=0).values\n",
    "        print(type(ft_item))\n",
    "        gt_item = self.gt.get_gts(init_time).to_array().isel(variable=0).values\n",
    "        print(type(gt_item))\n",
    "        return ft_item, gt_item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(list(self.init_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第六步**\n",
    "前五步已经完成了数据预处理加载的相关类和函数的准备, 这里我们可以通过实例化mydataset类来查看数据数量\n",
    "同时完成数据集的构建后, 我们可以通过DataLoader来查看数据集的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:42.078348Z",
     "iopub.status.busy": "2024-07-24T16:43:42.078134Z",
     "iopub.status.idle": "2024-07-24T16:43:42.581916Z",
     "shell.execute_reply": "2024-07-24T16:43:42.581456Z",
     "shell.execute_reply.started": "2024-07-24T16:43:42.078333Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample num: 4\n"
     ]
    }
   ],
   "source": [
    "# 可以查看一下已经构建的dataset\n",
    "# define dataset\n",
    "my_data = mydataset()\n",
    "print('sample num:', mydataset().__len__())\n",
    "train_loader = DataLoader(my_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第七步**\n",
    "- 完成了数据的准备工作, 接下来就是构建模型的部分\n",
    "- Model这个类, 对我们的模型进行定义, 方便后续训练时调用\n",
    "- 这里我们以一个简单的只有一个卷积层的网络为例\n",
    "- 在本次比赛中, 我们的输入数据维度是(1, 24, 72, W, H), 输出数据维度是(1, 72, W, H) 可以在赛题中查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:42.582998Z",
     "iopub.status.busy": "2024-07-24T16:43:42.582550Z",
     "iopub.status.idle": "2024-07-24T16:43:42.740513Z",
     "shell.execute_reply": "2024-07-24T16:43:42.739828Z",
     "shell.execute_reply.started": "2024-07-24T16:43:42.582980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型构建部分\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_in_ch, num_out_ch):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_in_ch, num_out_ch, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, C, W, H = tuple(x.shape)\n",
    "        x = x.reshape(B, -1, W, H)\n",
    "        out = self.conv1(x)\n",
    "        out = out.reshape(B, S, W, H)\n",
    "        return out\n",
    "\n",
    "# define model\n",
    "in_varibales = 24\n",
    "in_times = len(fcst_steps)\n",
    "out_varibales = 1\n",
    "out_times = len(fcst_steps)\n",
    "input_size = in_times * in_varibales\n",
    "output_size = out_times * out_varibales\n",
    "model = Model(input_size, output_size).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第八步**\n",
    "定义模型的损失函数部分， 用于模型训练做反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:42.741488Z",
     "iopub.status.busy": "2024-07-24T16:43:42.741255Z",
     "iopub.status.idle": "2024-07-24T16:43:42.744139Z",
     "shell.execute_reply": "2024-07-24T16:43:42.743652Z",
     "shell.execute_reply.started": "2024-07-24T16:43:42.741471Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define loss\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第九步**\n",
    "模型训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:42.745089Z",
     "iopub.status.busy": "2024-07-24T16:43:42.744902Z",
     "iopub.status.idle": "2024-07-24T16:43:45.441094Z",
     "shell.execute_reply": "2024-07-24T16:43:45.440580Z",
     "shell.execute_reply.started": "2024-07-24T16:43:42.745074Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from tqdm import tqdm\n",
    "# Train the model\n",
    "num_epochs = 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "for epoch in range(num_epochs):\n",
    "    for index, (ft_item, gt_item) in enumerate(train_loader):\n",
    "        ft_item = ft_item.cuda().float()\n",
    "        gt_item = gt_item.cuda().float()\n",
    "        print(type(ft_item))\n",
    "        print(type(gt_item))\n",
    "        \n",
    "        # Forward pass\n",
    "        output_item = model(ft_item)\n",
    "        loss = loss_func(output_item, gt_item)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print the loss for every 10 steps\n",
    "        if (index+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{index+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第十步**\n",
    "- 模型推理部分, 通过加载模型使用测试数据作为输入, 得到预测结果\n",
    "- 其中test_data_path需要给出从下载测试数据解压后的目录路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:43:45.442094Z",
     "iopub.status.busy": "2024-07-24T16:43:45.441849Z",
     "iopub.status.idle": "2024-07-24T16:43:54.761460Z",
     "shell.execute_reply": "2024-07-24T16:43:54.760935Z",
     "shell.execute_reply.started": "2024-07-24T16:43:45.442078Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape for sample 250: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 220: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 075: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 136: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 242: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 074: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 251: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 048: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 006: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 170: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 190: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 072: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 240: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 028: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 162: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 029: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 217: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 284: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 094: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 214: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 273: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 110: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 146: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 175: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 153: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 020: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 159: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 024: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 077: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 219: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 269: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 207: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 166: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 138: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 261: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 057: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 106: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 045: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 244: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 142: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 035: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 064: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 264: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 039: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 247: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 026: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 001: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 005: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 015: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 188: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 044: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 118: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 286: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 046: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 193: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 080: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 252: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 297: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 083: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 222: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 100: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 163: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 062: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 135: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 082: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 218: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 165: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 229: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 241: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 016: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 290: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 224: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 259: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 189: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 017: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 249: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 168: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 130: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 257: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 097: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 050: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 143: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 184: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 126: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 248: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 258: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 063: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 114: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 004: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 279: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 066: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 081: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 053: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 140: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 127: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 154: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 109: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 296: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 008: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 087: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 171: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 086: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 132: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 231: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 253: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 204: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 079: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 089: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 003: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 265: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 102: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 068: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 233: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 157: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 031: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 198: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 092: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 216: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 052: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 018: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 119: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 281: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 274: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 104: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 096: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 223: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 148: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 227: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 034: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 289: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 206: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 037: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 160: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 041: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 117: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 012: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 054: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 243: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 167: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 191: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 108: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 267: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 122: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 270: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 292: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 011: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 019: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 151: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 282: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 213: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 113: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 176: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 172: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 181: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 268: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 023: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 280: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 256: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 183: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 055: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 299: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 285: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 288: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 128: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 202: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 076: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 101: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 210: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 147: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 278: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 169: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 238: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 173: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 161: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 049: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 107: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 069: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 073: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 156: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 255: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 038: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 085: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 152: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 209: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 112: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 116: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 036: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 293: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 221: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 095: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 002: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 287: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 262: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 195: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 047: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 211: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 179: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 158: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 182: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 212: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 013: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 056: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 164: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 174: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 203: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 192: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 070: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 205: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 090: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 022: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 246: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 040: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 121: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 065: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 025: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 178: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 271: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 093: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 103: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 298: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 234: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 208: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 149: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 201: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 291: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 120: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 124: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 144: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 283: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 197: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 067: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 177: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 225: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 254: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 235: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 260: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 033: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 275: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 263: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 099: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 186: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 059: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 129: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 187: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 071: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 000: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 139: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 294: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 150: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 131: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 295: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 145: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 276: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 141: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 043: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 226: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 239: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 091: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 030: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 014: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 134: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 051: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 185: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 125: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 105: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 215: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 115: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 200: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 123: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 230: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 236: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 245: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 009: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 027: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 021: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 061: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 272: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 180: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 199: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 010: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 060: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 228: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 058: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 078: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 137: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 032: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 155: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 042: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 111: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 196: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 084: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 088: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 194: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 232: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 007: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 237: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 277: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 098: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 133: torch.Size([1, 72, 57, 81])\n",
      "Output shape for sample 266: torch.Size([1, 72, 57, 81])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()\n",
    "import os\n",
    "\n",
    "test_data_path = \"test/weather.round1.test\"\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "for index, test_data_file in enumerate(os.listdir(test_data_path)):\n",
    "    test_data = torch.load(os.path.join(test_data_path, test_data_file))\n",
    "    test_data = test_data.cuda().float()\n",
    "    \n",
    "    # Forward pass\n",
    "    output_item = model(test_data)\n",
    "    \n",
    "    # Print the output shape\n",
    "    print(f\"Output shape for sample {test_data_file.split('.')[0]}: {output_item.shape}\")\n",
    "    \n",
    "    # Save the output\n",
    "    output_path = f\"output/{test_data_file}\"\n",
    "    torch.save(output_item.cpu(), output_path)\n",
    "    # Load the model weights\n",
    "    model.load_state_dict(torch.load(\"model_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-24T16:44:47.890134Z",
     "iopub.status.busy": "2024-07-24T16:44:47.889811Z",
     "iopub.status.idle": "2024-07-24T16:45:04.852734Z",
     "shell.execute_reply": "2024-07-24T16:45:04.852127Z",
     "shell.execute_reply.started": "2024-07-24T16:44:47.890114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: output/ (stored 0%)\n",
      "  adding: output/250.pt (deflated 13%)\n",
      "  adding: output/220.pt (deflated 12%)\n",
      "  adding: output/075.pt (deflated 13%)\n",
      "  adding: output/136.pt (deflated 11%)\n",
      "  adding: output/242.pt (deflated 8%)\n",
      "  adding: output/074.pt (deflated 10%)\n",
      "  adding: output/251.pt (deflated 9%)\n",
      "  adding: output/048.pt (deflated 10%)\n",
      "  adding: output/006.pt (deflated 10%)\n",
      "  adding: output/170.pt (deflated 10%)\n",
      "  adding: output/190.pt (deflated 9%)\n",
      "  adding: output/072.pt (deflated 8%)\n",
      "  adding: output/240.pt (deflated 8%)\n",
      "  adding: output/028.pt (deflated 8%)\n",
      "  adding: output/162.pt (deflated 12%)\n",
      "  adding: output/029.pt (deflated 8%)\n",
      "  adding: output/217.pt (deflated 8%)\n",
      "  adding: output/284.pt (deflated 12%)\n",
      "  adding: output/094.pt (deflated 11%)\n",
      "  adding: output/214.pt (deflated 12%)\n",
      "  adding: output/273.pt (deflated 13%)\n",
      "  adding: output/110.pt (deflated 9%)\n",
      "  adding: output/146.pt (deflated 10%)\n",
      "  adding: output/175.pt (deflated 12%)\n",
      "  adding: output/153.pt (deflated 11%)\n",
      "  adding: output/020.pt (deflated 9%)\n",
      "  adding: output/159.pt (deflated 8%)\n",
      "  adding: output/024.pt (deflated 10%)\n",
      "  adding: output/077.pt (deflated 9%)\n",
      "  adding: output/219.pt (deflated 13%)\n",
      "  adding: output/269.pt (deflated 8%)\n",
      "  adding: output/207.pt (deflated 11%)\n",
      "  adding: output/166.pt (deflated 13%)\n",
      "  adding: output/138.pt (deflated 10%)\n",
      "  adding: output/261.pt (deflated 8%)\n",
      "  adding: output/057.pt (deflated 13%)\n",
      "  adding: output/106.pt (deflated 8%)\n",
      "  adding: output/045.pt (deflated 11%)\n",
      "  adding: output/244.pt (deflated 10%)\n",
      "  adding: output/142.pt (deflated 9%)\n",
      "  adding: output/035.pt (deflated 7%)\n",
      "  adding: output/064.pt (deflated 8%)\n",
      "  adding: output/264.pt (deflated 8%)\n",
      "  adding: output/039.pt (deflated 8%)\n",
      "  adding: output/247.pt (deflated 8%)\n",
      "  adding: output/026.pt (deflated 12%)\n",
      "  adding: output/001.pt (deflated 8%)\n",
      "  adding: output/005.pt (deflated 10%)\n",
      "  adding: output/015.pt (deflated 11%)\n",
      "  adding: output/188.pt (deflated 10%)\n",
      "  adding: output/044.pt (deflated 9%)\n",
      "  adding: output/118.pt (deflated 8%)\n",
      "  adding: output/286.pt (deflated 8%)\n",
      "  adding: output/046.pt (deflated 11%)\n",
      "  adding: output/193.pt (deflated 8%)\n",
      "  adding: output/080.pt (deflated 9%)\n",
      "  adding: output/252.pt (deflated 9%)\n",
      "  adding: output/297.pt (deflated 10%)\n",
      "  adding: output/083.pt (deflated 10%)\n",
      "  adding: output/222.pt (deflated 8%)\n",
      "  adding: output/100.pt (deflated 8%)\n",
      "  adding: output/163.pt (deflated 10%)\n",
      "  adding: output/062.pt (deflated 10%)\n",
      "  adding: output/135.pt (deflated 8%)\n",
      "  adding: output/082.pt (deflated 8%)\n",
      "  adding: output/218.pt (deflated 9%)\n",
      "  adding: output/165.pt (deflated 9%)\n",
      "  adding: output/229.pt (deflated 10%)\n",
      "  adding: output/241.pt (deflated 11%)\n",
      "  adding: output/016.pt (deflated 11%)\n",
      "  adding: output/290.pt (deflated 11%)\n",
      "  adding: output/224.pt (deflated 8%)\n",
      "  adding: output/259.pt (deflated 12%)\n",
      "  adding: output/189.pt (deflated 8%)\n",
      "  adding: output/017.pt (deflated 12%)\n",
      "  adding: output/249.pt (deflated 10%)\n",
      "  adding: output/168.pt (deflated 9%)\n",
      "  adding: output/130.pt (deflated 10%)\n",
      "  adding: output/257.pt (deflated 9%)\n",
      "  adding: output/097.pt (deflated 13%)\n",
      "  adding: output/050.pt (deflated 7%)\n",
      "  adding: output/143.pt (deflated 8%)\n",
      "  adding: output/184.pt (deflated 12%)\n",
      "  adding: output/126.pt (deflated 10%)\n",
      "  adding: output/248.pt (deflated 10%)\n",
      "  adding: output/258.pt (deflated 9%)\n",
      "  adding: output/063.pt (deflated 10%)\n",
      "  adding: output/114.pt (deflated 13%)\n",
      "  adding: output/004.pt (deflated 8%)\n",
      "  adding: output/279.pt (deflated 8%)\n",
      "  adding: output/066.pt (deflated 11%)\n",
      "  adding: output/081.pt (deflated 8%)\n",
      "  adding: output/053.pt (deflated 9%)\n",
      "  adding: output/140.pt (deflated 9%)\n",
      "  adding: output/127.pt (deflated 12%)\n",
      "  adding: output/154.pt (deflated 8%)\n",
      "  adding: output/109.pt (deflated 7%)\n",
      "  adding: output/296.pt (deflated 10%)\n",
      "  adding: output/008.pt (deflated 12%)\n",
      "  adding: output/087.pt (deflated 8%)\n",
      "  adding: output/171.pt (deflated 12%)\n",
      "  adding: output/086.pt (deflated 11%)\n",
      "  adding: output/132.pt (deflated 10%)\n",
      "  adding: output/231.pt (deflated 8%)\n",
      "  adding: output/253.pt (deflated 11%)\n",
      "  adding: output/204.pt (deflated 10%)\n",
      "  adding: output/079.pt (deflated 10%)\n",
      "  adding: output/089.pt (deflated 11%)\n",
      "  adding: output/003.pt (deflated 8%)\n",
      "  adding: output/265.pt (deflated 12%)\n",
      "  adding: output/102.pt (deflated 8%)\n",
      "  adding: output/068.pt (deflated 8%)\n",
      "  adding: output/233.pt (deflated 12%)\n",
      "  adding: output/157.pt (deflated 12%)\n",
      "  adding: output/031.pt (deflated 9%)\n",
      "  adding: output/198.pt (deflated 8%)\n",
      "  adding: output/092.pt (deflated 7%)\n",
      "  adding: output/216.pt (deflated 8%)\n",
      "  adding: output/052.pt (deflated 13%)\n",
      "  adding: output/018.pt (deflated 8%)\n",
      "  adding: output/119.pt (deflated 9%)\n",
      "  adding: output/281.pt (deflated 12%)\n",
      "  adding: output/274.pt (deflated 9%)\n",
      "  adding: output/104.pt (deflated 8%)\n",
      "  adding: output/096.pt (deflated 12%)\n",
      "  adding: output/223.pt (deflated 9%)\n",
      "  adding: output/148.pt (deflated 8%)\n",
      "  adding: output/227.pt (deflated 12%)\n",
      "  adding: output/034.pt (deflated 8%)\n",
      "  adding: output/289.pt (deflated 10%)\n",
      "  adding: output/206.pt (deflated 11%)\n",
      "  adding: output/037.pt (deflated 11%)\n",
      "  adding: output/160.pt (deflated 8%)\n",
      "  adding: output/041.pt (deflated 9%)\n",
      "  adding: output/117.pt (deflated 8%)\n",
      "  adding: output/012.pt (deflated 12%)\n",
      "  adding: output/054.pt (deflated 12%)\n",
      "  adding: output/243.pt (deflated 11%)\n",
      "  adding: output/167.pt (deflated 7%)\n",
      "  adding: output/191.pt (deflated 8%)\n",
      "  adding: output/108.pt (deflated 9%)\n",
      "  adding: output/267.pt (deflated 12%)\n",
      "  adding: output/122.pt (deflated 11%)\n",
      "  adding: output/270.pt (deflated 9%)\n",
      "  adding: output/292.pt (deflated 9%)\n",
      "  adding: output/011.pt (deflated 9%)\n",
      "  adding: output/019.pt (deflated 11%)\n",
      "  adding: output/151.pt (deflated 13%)\n",
      "  adding: output/282.pt (deflated 8%)\n",
      "  adding: output/213.pt (deflated 13%)\n",
      "  adding: output/113.pt (deflated 10%)\n",
      "  adding: output/176.pt (deflated 9%)\n",
      "  adding: output/172.pt (deflated 8%)\n",
      "  adding: output/181.pt (deflated 10%)\n",
      "  adding: output/268.pt (deflated 8%)\n",
      "  adding: output/023.pt (deflated 8%)\n",
      "  adding: output/280.pt (deflated 12%)\n",
      "  adding: output/256.pt (deflated 9%)\n",
      "  adding: output/183.pt (deflated 12%)\n",
      "  adding: output/055.pt (deflated 9%)\n",
      "  adding: output/299.pt (deflated 9%)\n",
      "  adding: output/285.pt (deflated 9%)\n",
      "  adding: output/288.pt (deflated 10%)\n",
      "  adding: output/128.pt (deflated 10%)\n",
      "  adding: output/202.pt (deflated 8%)\n",
      "  adding: output/076.pt (deflated 9%)\n",
      "  adding: output/101.pt (deflated 8%)\n",
      "  adding: output/210.pt (deflated 10%)\n",
      "  adding: output/147.pt (deflated 11%)\n",
      "  adding: output/278.pt (deflated 8%)\n",
      "  adding: output/169.pt (deflated 9%)\n",
      "  adding: output/238.pt (deflated 8%)\n",
      "  adding: output/173.pt (deflated 11%)\n",
      "  adding: output/161.pt (deflated 11%)\n",
      "  adding: output/049.pt (deflated 8%)\n",
      "  adding: output/107.pt (deflated 12%)\n",
      "  adding: output/069.pt (deflated 7%)\n",
      "  adding: output/073.pt (deflated 9%)\n",
      "  adding: output/156.pt (deflated 9%)\n",
      "  adding: output/255.pt (deflated 10%)\n",
      "  adding: output/038.pt (deflated 11%)\n",
      "  adding: output/085.pt (deflated 9%)\n",
      "  adding: output/152.pt (deflated 11%)\n",
      "  adding: output/209.pt (deflated 8%)\n",
      "  adding: output/112.pt (deflated 9%)\n",
      "  adding: output/116.pt (deflated 12%)\n",
      "  adding: output/036.pt (deflated 8%)\n",
      "  adding: output/293.pt (deflated 10%)\n",
      "  adding: output/221.pt (deflated 8%)\n",
      "  adding: output/095.pt (deflated 8%)\n",
      "  adding: output/002.pt (deflated 9%)\n",
      "  adding: output/287.pt (deflated 9%)\n",
      "  adding: output/262.pt (deflated 11%)\n",
      "  adding: output/195.pt (deflated 12%)\n",
      "  adding: output/047.pt (deflated 10%)\n",
      "  adding: output/211.pt (deflated 11%)\n",
      "  adding: output/179.pt (deflated 9%)\n",
      "  adding: output/158.pt (deflated 8%)\n",
      "  adding: output/182.pt (deflated 12%)\n",
      "  adding: output/212.pt (deflated 9%)\n",
      "  adding: output/013.pt (deflated 8%)\n",
      "  adding: output/056.pt (deflated 13%)\n",
      "  adding: output/164.pt (deflated 9%)\n",
      "  adding: output/174.pt (deflated 9%)\n",
      "  adding: output/203.pt (deflated 8%)\n",
      "  adding: output/192.pt (deflated 10%)\n",
      "  adding: output/070.pt (deflated 11%)\n",
      "  adding: output/205.pt (deflated 8%)\n",
      "  adding: output/090.pt (deflated 13%)\n",
      "  adding: output/022.pt (deflated 9%)\n",
      "  adding: output/246.pt (deflated 8%)\n",
      "  adding: output/040.pt (deflated 10%)\n",
      "  adding: output/121.pt (deflated 8%)\n",
      "  adding: output/065.pt (deflated 10%)\n",
      "  adding: output/025.pt (deflated 8%)\n",
      "  adding: output/178.pt (deflated 8%)\n",
      "  adding: output/271.pt (deflated 9%)\n",
      "  adding: output/093.pt (deflated 9%)\n",
      "  adding: output/103.pt (deflated 10%)\n",
      "  adding: output/298.pt (deflated 9%)\n",
      "  adding: output/234.pt (deflated 8%)\n",
      "  adding: output/208.pt (deflated 12%)\n",
      "  adding: output/149.pt (deflated 11%)\n",
      "  adding: output/201.pt (deflated 10%)\n",
      "  adding: output/291.pt (deflated 9%)\n",
      "  adding: output/120.pt (deflated 13%)\n",
      "  adding: output/124.pt (deflated 10%)\n",
      "  adding: output/144.pt (deflated 9%)\n",
      "  adding: output/283.pt (deflated 8%)\n",
      "  adding: output/197.pt (deflated 9%)\n",
      "  adding: output/067.pt (deflated 8%)\n",
      "  adding: output/177.pt (deflated 12%)\n",
      "  adding: output/225.pt (deflated 9%)\n",
      "  adding: output/254.pt (deflated 10%)\n",
      "  adding: output/235.pt (deflated 8%)\n",
      "  adding: output/260.pt (deflated 10%)\n",
      "  adding: output/033.pt (deflated 9%)\n",
      "  adding: output/275.pt (deflated 9%)\n",
      "  adding: output/263.pt (deflated 9%)\n",
      "  adding: output/099.pt (deflated 10%)\n",
      "  adding: output/186.pt (deflated 8%)\n",
      "  adding: output/059.pt (deflated 9%)\n",
      "  adding: output/129.pt (deflated 8%)\n",
      "  adding: output/187.pt (deflated 8%)\n",
      "  adding: output/071.pt (deflated 9%)\n",
      "  adding: output/000.pt (deflated 8%)\n",
      "  adding: output/139.pt (deflated 10%)\n",
      "  adding: output/294.pt (deflated 9%)\n",
      "  adding: output/150.pt (deflated 9%)\n",
      "  adding: output/131.pt (deflated 9%)\n",
      "  adding: output/295.pt (deflated 9%)\n",
      "  adding: output/145.pt (deflated 9%)\n",
      "  adding: output/276.pt (deflated 13%)\n",
      "  adding: output/141.pt (deflated 12%)\n",
      "  adding: output/043.pt (deflated 12%)\n",
      "  adding: output/226.pt (deflated 7%)\n",
      "  adding: output/239.pt (deflated 12%)\n",
      "  adding: output/091.pt (deflated 8%)\n",
      "  adding: output/030.pt (deflated 8%)\n",
      "  adding: output/014.pt (deflated 9%)\n",
      "  adding: output/134.pt (deflated 8%)\n",
      "  adding: output/051.pt (deflated 8%)\n",
      "  adding: output/185.pt (deflated 10%)\n",
      "  adding: output/125.pt (deflated 10%)\n",
      "  adding: output/105.pt (deflated 8%)\n",
      "  adding: output/215.pt (deflated 10%)\n",
      "  adding: output/115.pt (deflated 8%)\n",
      "  adding: output/200.pt (deflated 10%)\n",
      "  adding: output/123.pt (deflated 10%)\n",
      "  adding: output/230.pt (deflated 11%)\n",
      "  adding: output/236.pt (deflated 8%)\n",
      "  adding: output/245.pt (deflated 13%)\n",
      "  adding: output/009.pt (deflated 9%)\n",
      "  adding: output/027.pt (deflated 9%)\n",
      "  adding: output/021.pt (deflated 8%)\n",
      "  adding: output/061.pt (deflated 10%)\n",
      "  adding: output/272.pt (deflated 8%)\n",
      "  adding: output/180.pt (deflated 10%)\n",
      "  adding: output/199.pt (deflated 13%)\n",
      "  adding: output/010.pt (deflated 10%)\n",
      "  adding: output/060.pt (deflated 8%)\n",
      "  adding: output/228.pt (deflated 9%)\n",
      "  adding: output/058.pt (deflated 9%)\n",
      "  adding: output/078.pt (deflated 8%)\n",
      "  adding: output/137.pt (deflated 8%)\n",
      "  adding: output/032.pt (deflated 11%)\n",
      "  adding: output/155.pt (deflated 9%)\n",
      "  adding: output/042.pt (deflated 10%)\n",
      "  adding: output/111.pt (deflated 11%)\n",
      "  adding: output/196.pt (deflated 12%)\n",
      "  adding: output/084.pt (deflated 8%)\n",
      "  adding: output/088.pt (deflated 10%)\n",
      "  adding: output/194.pt (deflated 13%)\n",
      "  adding: output/232.pt (deflated 8%)\n",
      "  adding: output/007.pt (deflated 10%)\n",
      "  adding: output/237.pt (deflated 10%)\n",
      "  adding: output/277.pt (deflated 8%)\n",
      "  adding: output/098.pt (deflated 12%)\n",
      "  adding: output/133.pt (deflated 8%)\n",
      "  adding: output/266.pt (deflated 8%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r output.zip output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
